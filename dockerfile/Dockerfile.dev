FROM nvcr.io/nvidia/tritonserver:23.07-py3

COPY requirements.txt /tmp/
RUN pip3 install -r /tmp/requirements.txt --extra-index-url https://pypi.ngc.nvidia.com

COPY tekit/requirements-dev.txt /tmp/
RUN pip install -r /tmp/requirements-dev.txt --extra-index-url https://pypi.ngc.nvidia.com

# Remove prevous TRT installation
# We didn't remove libnvinfer* here because tritonserver depends on the pre-installed libraries.
RUN apt-get remove --purge -y tensorrt*
RUN pip uninstall -y tensorrt

# Download TensorRT-<version>.Linux.x86_64-gnu.cuda-<m.n>.tar.gz to pwd before building docker image
COPY TensorRT-9.0.1.1.Linux.x86_64-gnu.cuda-12.2.tar.gz /workspace/
RUN tar -xvf /workspace/TensorRT-9.0.1.1.Linux.x86_64-gnu.cuda-12.2.tar.gz -C /usr/local/ && mv /usr/local/TensorRT-9.0.1.1 /usr/local/tensorrt
RUN pip install /usr/local/tensorrt/python/tensorrt-9.0.1*cp310-none-linux_x86_64.whl && rm -fr /workspace/TensorRT-9.0.1.1.Linux.x86_64-gnu.cuda-12.2.tar.gz
ENV LD_LIBRARY_PATH=/usr/local/tensorrt/lib/:$LD_LIBRARY_PATH

# Download polygraphy-0.48.1-py2.py3-none-any.whl to pwd before building the docker image
COPY polygraphy-0.48.1-py2.py3-none-any.whl /workspace/
RUN pip install /workspace/polygraphy-0.48.1-py2.py3-none-any.whl

# CMake
RUN wget https://github.com/Kitware/CMake/releases/download/v3.18.1/cmake-3.18.1-Linux-x86_64.sh
RUN bash cmake-3.18.1-Linux-x86_64.sh --prefix=/usr/local --exclude-subdir
ENV PATH="/usr/local/bin:${PATH}"
