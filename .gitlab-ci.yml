variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  GIT_SUBMODULE_STRATEGY: recursive
  IMAGE: urm.nvidia.com/sw-tensorrt-docker/tensorrt-llm:dev-trt9.0.1.4_triton23.07
  TRT_ROOT: /usr/local/tensorrt

default:
  before_script:
    - export LD_LIBRARY_PATH="$TRT_ROOT/lib/:$LD_LIBRARY_PATH"
    - echo $LD_LIBRARY_PATH

cache:
  paths:
    - .cache/pip

stages:
  - style-check
  - build-trt-llm
  - build-trt-llm-backend
  - test-model

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"
    - if: $CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "schedule"

style-check-job:
  stage: style-check
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install pre-commit
    - pre-commit run -a

build-tensorrt-llm:
  stage: build-trt-llm
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - python3 tekit/scripts/build_wheel.py -a "80;86" --trt_root $TRT_ROOT
    - cd $CI_PROJECT_DIR/inflight_batcher_llm
    - bash scripts/build.sh
  artifacts:
    expire_in: 30 mins
    paths:
      - tekit/build
      - tekit/cpp/build
      - inflight_batcher_llm/build

test-gpt-model-job:
  stage: test-model
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install --extra-index-url https://pypi.ngc.nvidia.com tekit/build/tensorrt_llm*.whl
    - bash scripts/tests/build_model.sh gpt
    - bash scripts/tests/test.sh gpt tekit/examples/gpt/trt_engine/gpt2/fp16/1-gpu/
  artifacts:
    expire_in: 30 mins
  dependencies:
    - build-tensorrt-llm

test-opt-model-job:
  stage: test-model
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install --extra-index-url https://pypi.ngc.nvidia.com tekit/build/tensorrt_llm*.whl
    - bash scripts/tests/build_model.sh opt
    - bash scripts/tests/test.sh opt tekit/examples/opt/trt_engine/opt-125m/fp16/1-gpu/
  artifacts:
    expire_in: 30 mins
  dependencies:
    - build-tensorrt-llm

test-llama-model-job:
  stage: test-model
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install --extra-index-url https://pypi.ngc.nvidia.com tekit/build/tensorrt_llm*.whl
    - bash scripts/tests/build_model.sh llama
    - bash scripts/tests/test.sh llama tekit/examples/llama/llama_outputs
  artifacts:
    expire_in: 30 mins
  dependencies:
    - build-tensorrt-llm

test-gptj-model-job:
  stage: test-model
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install --extra-index-url https://pypi.ngc.nvidia.com tekit/build/tensorrt_llm*.whl
    - bash scripts/tests/build_model.sh gptj
    - bash scripts/tests/test.sh gptj tekit/examples/gptj/gpt_outputs
  artifacts:
    expire_in: 30 mins
  dependencies:
    - build-tensorrt-llm

test-gpt-ib-model-job:
  stage: test-model
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install --extra-index-url https://pypi.ngc.nvidia.com tekit/build/tensorrt_llm*.whl
    - mkdir /opt/tritonserver/backends/inflight_batcher_llm
    - cp inflight_batcher_llm/build/libtriton_inflight_batcher_llm.so /opt/tritonserver/backends/inflight_batcher_llm
    - bash scripts/tests/build_model.sh gpt-ib
    - bash scripts/tests/test.sh gpt-ib tekit/examples/gpt/trt_engine/gpt2-ib/fp16/1-gpu/
  artifacts:
    expire_in: 30 mins
  dependencies:
    - build-tensorrt-llm

test-gpt-ib-streaming-model-job:
  stage: test-model
  image: $IMAGE
  script:
    - cd $CI_PROJECT_DIR
    - pip3 install --extra-index-url https://pypi.ngc.nvidia.com tekit/build/tensorrt_llm*.whl
    - mkdir /opt/tritonserver/backends/inflight_batcher_llm
    - cp inflight_batcher_llm/build/libtriton_inflight_batcher_llm.so /opt/tritonserver/backends/inflight_batcher_llm
    - bash scripts/tests/build_model.sh gpt-ib
    - bash scripts/tests/test.sh gpt-ib-streaming tekit/examples/gpt/trt_engine/gpt2-ib/fp16/1-gpu/
  artifacts:
    expire_in: 30 mins
  dependencies:
    - build-tensorrt-llm
